[build-system]
requires = ["setuptools>=61.0"]
build-backend = "setuptools.build_meta"

[project]
name = "LLaVA-VQA"
version = "0.0.1"
description = "Training and evaluation code for LLaVA on VQA"
readme = "README.md"
requires-python = ">=3.10"
dependencies = [
    "accelerate",
    "black",
    "black[jupyter]",
    "bitsandbytes",
    "einops",
    "einops-exts",
    "fastapi",
    "fire",
    "gradio",
    "gradio_client",
    "httpx",
    "isort",
    "markdown2[all]",
    "mypy",
    "numpy",
    "peft",
    "pydantic",
    "pylint",
    "requests",
    "torch==2.3.0+cu121",  # Google Colab Instances
    "torchvision",
    "transformers==4.37.2",  # Fixes 'LlavaLlamaForCausalLM.forward()' 'cache_position' issue
    "tokenizers",
    "scikit-learn",
    "sentencepiece",
    "shortuuid",
    "timm",
    "uvicorn",
]

[project.optional-dependencies]
train = ["deepspeed==0.12.6", "ninja", "wandb"]
build = ["build", "twine"]

[tool.black]
line-length = 120

[tool.isort]
profile = "black"

[tool.mypy]

[[tool.mypy.overrides]]
module = [
    'fire.*',
    'llava.*',
    'numpy.*',
    'torch.*',
    'tqdm.*',
]
ignore_missing_imports = true